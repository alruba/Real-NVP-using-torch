{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import util\n",
    "\n",
    "from models import RealNVP, RealNVPLoss\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    device = 'cuda' if torch.cuda.is_available() and len(args.gpu_ids) > 0 else 'cpu'\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Note: No normalization applied, since RealNVP expects inputs in (0, 1).\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.GPRDataset(root='data', train=True, download=False, transform=transform_train)\n",
    "    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "    testset = torchvision.datasets.GPRDataset(root='data', train=False, download=False, transform=transform_test)\n",
    "    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "    # Model\n",
    "    print('Building model..')\n",
    "    net = RealNVP(num_scales=2, in_channels=3, mid_channels=64, num_blocks=8)\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net = torch.nn.DataParallel(net, args.gpu_ids)\n",
    "        cudnn.benchmark = args.benchmark\n",
    "\n",
    "    if args.resume:\n",
    "        # Load checkpoint.\n",
    "        print('Resuming from checkpoint at ckpts/best.pth.tar...')\n",
    "        assert os.path.isdir('ckpts'), 'Error: no checkpoint directory found!'\n",
    "        checkpoint = torch.load('ckpts/best.pth.tar')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        global best_loss\n",
    "        best_loss = checkpoint['test_loss']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "\n",
    "    loss_fn = RealNVPLoss()\n",
    "    param_groups = util.get_param_groups(net, args.weight_decay, norm_suffix='weight_g')\n",
    "    optimizer = optim.Adam(param_groups, lr=args.lr)\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + args.num_epochs):\n",
    "        train(epoch, net, trainloader, device, optimizer, loss_fn, args.max_grad_norm)\n",
    "        test(epoch, net, testloader, device, loss_fn, args.num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net, trainloader, device, optimizer, loss_fn, max_grad_norm):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    loss_meter = util.AverageMeter()\n",
    "    with tqdm(total=len(trainloader.dataset)) as progress_bar:\n",
    "        for x, _ in trainloader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z, sldj = net(x, reverse=False)\n",
    "            loss = loss_fn(z, sldj)\n",
    "            loss_meter.update(loss.item(), x.size(0))\n",
    "            loss.backward()\n",
    "            util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                     bpd=util.bits_per_dim(x, loss_meter.avg))\n",
    "            progress_bar.update(x.size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE] [--benchmark]\n",
      "                             [--gpu_ids GPU_IDS] [--lr LR]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_epochs NUM_EPOCHS]\n",
      "                             [--num_samples NUM_SAMPLES]\n",
      "                             [--num_workers NUM_WORKERS] [--resume]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/test/Library/Jupyter/runtime/kernel-d75d4113-ed6c-4568-a30e-289c9f53c913.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rnvp/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3425: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def sample(net, batch_size, device):\n",
    "    \"\"\"Sample from RealNVP model.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.DataParallel): The RealNVP model wrapped in DataParallel.\n",
    "        batch_size (int): Number of samples to generate.\n",
    "        device (torch.device): Device to use.\n",
    "    \"\"\"\n",
    "    z = torch.randn((batch_size, 3, 32, 32), dtype=torch.float32, device=device)\n",
    "    x, _ = net(z, reverse=True)\n",
    "    x = torch.sigmoid(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def test(epoch, net, testloader, device, loss_fn, num_samples):\n",
    "    global best_loss\n",
    "    net.eval()\n",
    "    loss_meter = util.AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
    "            for x, _ in testloader:\n",
    "                x = x.to(device)\n",
    "                z, sldj = net(x, reverse=False)\n",
    "                loss = loss_fn(z, sldj)\n",
    "                loss_meter.update(loss.item(), x.size(0))\n",
    "                progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                         bpd=util.bits_per_dim(x, loss_meter.avg))\n",
    "                progress_bar.update(x.size(0))\n",
    "\n",
    "    # Save checkpoint\n",
    "    if loss_meter.avg < best_loss:\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'test_loss': loss_meter.avg,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        os.makedirs('ckpts', exist_ok=True)\n",
    "        torch.save(state, 'ckpts/best.pth.tar')\n",
    "        best_loss = loss_meter.avg\n",
    "\n",
    "    # Save samples and data\n",
    "    images = sample(net, num_samples, device)\n",
    "    os.makedirs('samples', exist_ok=True)\n",
    "    images_concat = torchvision.utils.make_grid(images, nrow=int(num_samples ** 0.5), padding=2, pad_value=255)\n",
    "    torchvision.utils.save_image(images_concat, 'samples/epoch_{}.png'.format(epoch))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='RealNVP on GPR')\n",
    "\n",
    "    parser.add_argument('--batch_size', default=64, type=int, help='Batch size')\n",
    "    parser.add_argument('--benchmark', action='store_true', help='Turn on CUDNN benchmarking')\n",
    "    parser.add_argument('--gpu_ids', default='[0]', type=eval, help='IDs of GPUs to use')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    parser.add_argument('--max_grad_norm', type=float, default=100., help='Max gradient norm for clipping')\n",
    "    parser.add_argument('--num_epochs', default=100, type=int, help='Number of epochs to train')\n",
    "    parser.add_argument('--num_samples', default=64, type=int, help='Number of samples at test time')\n",
    "    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loader threads')\n",
    "    parser.add_argument('--resume', '-r', action='store_true', help='Resume from checkpoint')\n",
    "    parser.add_argument('--weight_decay', default=5e-5, type=float,\n",
    "                        help='L2 regularization (only applied to the weight norm scale factors)')\n",
    "\n",
    "    best_loss = 0\n",
    "\n",
    "    main(parser.parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
